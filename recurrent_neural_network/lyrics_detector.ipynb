{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics detector Challenge\n",
    "\n",
    "The goal for this challenge is to leverage your knowledge of Deep Learning to design and train a lyrics classifier. For a given verse $X$, our model should learn to predict the artist $y$. The dataset consists of lyrics scrapped from the Genius website.\n",
    "\n",
    "### Objectives:\n",
    "- Text preprocessing\n",
    "- Text embedding\n",
    "- Train a RNN to detect the artist behind a set of lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.205260Z",
     "start_time": "2021-06-25T17:22:11.396250Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "\n",
    "Our dataset contains around 4,000 verses of lyrics from different artists: Drake, Ed Sheeran and Kanye West (the verses are given in this order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.654079Z",
     "start_time": "2021-06-25T17:22:16.207433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah\n",
       "1          Drake  I'm makin' a change today The liquor been taki...\n",
       "2          Drake  I can't just be with you and only you Yeah, I ...\n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...\n",
       "4          Drake  I'm makin' a change today The liquor been taki...\n",
       "...          ...                                                ...\n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...\n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...\n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"\n",
       "3973  Kanye West  Like they still weren't looking at me like a r...\n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...\n",
       "\n",
       "[3975 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/verses.csv\")\n",
    "data = raw_data.copy() # From now on, update `data` as you see fit and don't touch raw_data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Have a look at the verse index 18th**. \n",
    "- What do you observe?\n",
    "- Clean verses from non standard characters using [`unidecode.unidecode()`](https://pypi.org/project/Unidecode/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unidecode in /home/thechwal/.local/lib/python3.8/site-packages (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"verse\"] = data[\"verse\"].apply(unidecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah\n",
       "1          Drake  I'm makin' a change today The liquor been taki...\n",
       "2          Drake  I can't just be with you and only you Yeah, I ...\n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...\n",
       "4          Drake  I'm makin' a change today The liquor been taki...\n",
       "...          ...                                                ...\n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...\n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...\n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"\n",
       "3973  Kanye West  Like they still weren't looking at me like a r...\n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...\n",
       "\n",
       "[3975 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Check if some verses are duplicated.** \n",
    "- It can be frequent in music lyrics.\n",
    "- If so, remove them to avoid data leaks between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.851521Z",
     "start_time": "2021-06-25T17:22:16.842793Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3975, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.861084Z",
     "start_time": "2021-06-25T17:22:16.854026Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_loading',\n",
    "    shape=data_cleaned.shape,\n",
    "    verses=data_cleaned.verse[:50]\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis (given to you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **We check the number of unique artist and the number of verses per artist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.182432Z",
     "start_time": "2021-06-25T17:22:19.175936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drake         1391\n",
       "Ed Sheeran     861\n",
       "Kanye West     779\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.artist.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **For each artist, let's have a look at the top-10 most used words to see if they look similar?**\n",
    "\n",
    "We'll use Tensorflow's [`Tokenizer`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)'s index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.191343Z",
     "start_time": "2021-06-25T17:22:19.184174Z"
    }
   },
   "outputs": [],
   "source": [
    "drake = data[data.artist =='Drake'].verse\n",
    "ed = data[data.artist =='Ed Sheeran'].verse\n",
    "kanye = data[data.artist =='Kanye West'].verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.438880Z",
     "start_time": "2021-06-25T17:22:19.193277Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_drake = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_ed = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_kanye = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer_drake.fit_on_texts(drake)\n",
    "tokenizer_ed.fit_on_texts(ed)\n",
    "tokenizer_kanye.fit_on_texts(kanye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.457776Z",
     "start_time": "2021-06-25T17:22:19.441016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drake</th>\n",
       "      <th>Ed Sheeran</th>\n",
       "      <th>Kanye West</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>me</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>my</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>to</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>me</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i'm</td>\n",
       "      <td>in</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>my</td>\n",
       "      <td>i'm</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Drake Ed Sheeran Kanye West\n",
       "1      i          i          i\n",
       "2    you        you        the\n",
       "3    the        the        you\n",
       "4    and        and        and\n",
       "5     to         me         to\n",
       "6      a         my          a\n",
       "7     it         to         my\n",
       "8     me          a         it\n",
       "9    i'm         in         me\n",
       "10    my        i'm         in"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={\n",
    "    \"Drake\": pd.Series(tokenizer_drake.index_word)[:10],\n",
    "    \"Ed Sheeran\": pd.Series(tokenizer_ed.index_word)[:10],\n",
    "    \"Kanye West\": pd.Series(tokenizer_kanye.index_word)[:10],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **Let's quantify how much vocabulary do they have in common**\n",
    "\n",
    "- An artist **vocabulary** is the **set** of all unique used words\n",
    "- We compute the `ratio` of (i) the length of vocabulary they **share**, over (ii) the length of the **total** vocabulary of the dataset\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "We'll use Python [`set.intersection()`](https://www.programiz.com/python-programming/methods/set/intersection) and [`set.union()`](https://www.programiz.com/python-programming/methods/set/union)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.465228Z",
     "start_time": "2021-06-25T17:22:19.460132Z"
    }
   },
   "outputs": [],
   "source": [
    "drake_vocabulary = set(tokenizer_drake.index_word.values())\n",
    "ed_vocabulary = set(tokenizer_ed.index_word.values())\n",
    "kanye_vocabulary = set(tokenizer_kanye.index_word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.474902Z",
     "start_time": "2021-06-25T17:22:19.467454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.28% of the artists' vocabulary is common\n"
     ]
    }
   ],
   "source": [
    "common_vocabulary = drake_vocabulary.intersection(ed_vocabulary).intersection(kanye_vocabulary)\n",
    "global_vocabulary = drake_vocabulary.union(ed_vocabulary).union(kanye_vocabulary)\n",
    "\n",
    "ratio = len(common_vocabulary)/len(global_vocabulary)\n",
    "print(f\"{ratio*100:.2f}% of the artists' vocabulary is common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Word Embedding\n",
    "We now need to think about embedding our sentences into numbers. We will be using [`gensim.models.Word2Vec`](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) to embed each word of the sentence and concatenate the embeddings of the words forming the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Transform the list of strings (verses) into a list of word sequences (a word sequence is a list of words contained in a string)**\n",
    "- Store these sequences of words in a new column `data[\"seq\"]` in your dataframe\n",
    "- You can use `tensorflow.keras.preprocessing.text.text_to_word_sequence` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.569442Z",
     "start_time": "2021-06-25T17:22:19.478291Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-805f1f9ccfca>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"seq\"] = data[\"verse\"].apply(tf.keras.preprocessing.text.text_to_word_sequence)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data[\"seq\"] = data[\"verse\"].apply(tf.keras.preprocessing.text.text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "      <td>[ayy, woah, ayy, ayy, yeah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "      <td>[i, can't, just, be, with, you, and, only, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "      <td>[well, summer, all, i, did, was, rest, okay, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "      <td>[dame, was, like, yo, you, got, a, deal, with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "      <td>[then, one, day, i, just, went, ahead, and, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "      <td>[i, ain't, gonna, front, it's, kinda, hot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "      <td>[like, they, still, weren't, looking, at, me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "      <td>[you, gotta, be, under, an, umbrella, you'll, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse  \\\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah   \n",
       "1          Drake  I'm makin' a change today The liquor been taki...   \n",
       "2          Drake  I can't just be with you and only you Yeah, I ...   \n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...   \n",
       "4          Drake  I'm makin' a change today The liquor been taki...   \n",
       "...          ...                                                ...   \n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...   \n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...   \n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"   \n",
       "3973  Kanye West  Like they still weren't looking at me like a r...   \n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...   \n",
       "\n",
       "                                                    seq  \n",
       "0                           [ayy, woah, ayy, ayy, yeah]  \n",
       "1     [i'm, makin', a, change, today, the, liquor, b...  \n",
       "2     [i, can't, just, be, with, you, and, only, you...  \n",
       "3     [well, summer, all, i, did, was, rest, okay, a...  \n",
       "4     [i'm, makin', a, change, today, the, liquor, b...  \n",
       "...                                                 ...  \n",
       "3970  [dame, was, like, yo, you, got, a, deal, with,...  \n",
       "3971  [then, one, day, i, just, went, ahead, and, pl...  \n",
       "3972         [i, ain't, gonna, front, it's, kinda, hot]  \n",
       "3973  [like, they, still, weren't, looking, at, me, ...  \n",
       "3974  [you, gotta, be, under, an, umbrella, you'll, ...  \n",
       "\n",
       "[3031 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Let's check if we can cap the length of each sequences without losing too much information**\n",
    "- Plot the distribution of sequences lengths using the [`seaborn.kdeplot`](https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn-displot) function\n",
    "- Does it seem reasonable to limit ourself to 300 words per verse later on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.783874Z",
     "start_time": "2021-06-25T17:22:19.572393Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-03ec62810863>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"len\"]= data[\"seq\"].apply(lambda x : len(x))\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data[\"len\"]= data[\"seq\"].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f2973fcfa60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data=data, x=\"len\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Keep only the first `300` words of each sequences to reduce the useless long tail of long verses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.797635Z",
     "start_time": "2021-06-25T17:22:19.786221Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-55c2bfd6189c>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"seq\"] = data[\"seq\"].apply(lambda x : x[:300])\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data[\"seq\"] = data[\"seq\"].apply(lambda x : x[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "      <th>seq</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "      <td>[ayy, woah, ayy, ayy, yeah]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "      <td>[i, can't, just, be, with, you, and, only, you...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "      <td>[well, summer, all, i, did, was, rest, okay, a...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "      <td>[dame, was, like, yo, you, got, a, deal, with,...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "      <td>[then, one, day, i, just, went, ahead, and, pl...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "      <td>[i, ain't, gonna, front, it's, kinda, hot]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "      <td>[like, they, still, weren't, looking, at, me, ...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "      <td>[you, gotta, be, under, an, umbrella, you'll, ...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3031 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse  \\\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah   \n",
       "1          Drake  I'm makin' a change today The liquor been taki...   \n",
       "2          Drake  I can't just be with you and only you Yeah, I ...   \n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...   \n",
       "4          Drake  I'm makin' a change today The liquor been taki...   \n",
       "...          ...                                                ...   \n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...   \n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...   \n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"   \n",
       "3973  Kanye West  Like they still weren't looking at me like a r...   \n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...   \n",
       "\n",
       "                                                    seq  len  \n",
       "0                           [ayy, woah, ayy, ayy, yeah]    5  \n",
       "1     [i'm, makin', a, change, today, the, liquor, b...   60  \n",
       "2     [i, can't, just, be, with, you, and, only, you...   96  \n",
       "3     [well, summer, all, i, did, was, rest, okay, a...   65  \n",
       "4     [i'm, makin', a, change, today, the, liquor, b...   61  \n",
       "...                                                 ...  ...  \n",
       "3970  [dame, was, like, yo, you, got, a, deal, with,...   18  \n",
       "3971  [then, one, day, i, just, went, ahead, and, pl...  110  \n",
       "3972         [i, ain't, gonna, front, it's, kinda, hot]    7  \n",
       "3973  [like, they, still, weren't, looking, at, me, ...   68  \n",
       "3974  [you, gotta, be, under, an, umbrella, you'll, ...  165  \n",
       "\n",
       "[3031 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Train a `gensim.models.Word2Vec` model on your dataset** \n",
    "- You want to embed each word into vectors of dimension `100`\n",
    "- No words should be excluded\n",
    "- Give Word2Vec at least 50 epochs to be sure it converges\n",
    "- Store these lists of vectors in a new column `data[\"embed\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/thechwal/.local/lib/python3.8/site-packages (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/thechwal/.local/lib/python3.8/site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/thechwal/.local/lib/python3.8/site-packages (from gensim) (1.7.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/thechwal/.local/lib/python3.8/site-packages (from gensim) (5.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:26.587185Z",
     "start_time": "2021-06-25T17:22:19.799947Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thechwal/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from gensim.models import Word2Vec\n",
    "word2vec = Word2Vec(sentences=data['seq'], vector_size=100, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "    return np.array(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-7608788501c3>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"embed\"] = data['seq'].apply(lambda x : embed_sentence(word2vec, x))\n"
     ]
    }
   ],
   "source": [
    "data[\"embed\"] = data['seq'].apply(lambda x : embed_sentence(word2vec, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:27.636650Z",
     "start_time": "2021-06-25T17:22:27.634359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check \n",
    "assert len(data['embed']) == len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create your numpy array `X` of shape (number_of_verses, 300, 100)**\n",
    "\n",
    "- 300 words per verse (pad verses shorter than 300 with zeros at the end) \n",
    "- each words being a vector of size 100\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lewagon/data-images/master/DL/padding.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.272086Z",
     "start_time": "2021-06-25T17:22:27.638449Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(data['embed'], dtype='float32', padding='post', maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 300, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create the numpy array `y` of shape `(n_verses, 3)` that contains the one-hot-encoded list of labels, for the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.394015Z",
     "start_time": "2021-06-25T17:22:28.274638Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y = ohe.fit_transform(data[[\"artist\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 We train/test split the dataset below for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.558686Z",
     "start_time": "2021-06-25T17:22:28.400774Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.803743Z",
     "start_time": "2021-06-25T17:22:29.563431Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_preprocessing',\n",
    "    n_zeros = np.sum(X == 0),\n",
    "    X_shape = X.shape,\n",
    "    y_shape = y.shape,\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-29 18:19:02--  https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_lyrics_solution.pickle\n",
      "Resolving wagon-public-datasets.s3.amazonaws.com (wagon-public-datasets.s3.amazonaws.com)... 52.218.41.50\n",
      "Connecting to wagon-public-datasets.s3.amazonaws.com (wagon-public-datasets.s3.amazonaws.com)|52.218.41.50|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 727513032 (694M) [application/octet-stream]\n",
      "Saving to: ‘data_lyrics_solution.pickle’\n",
      "\n",
      "data_lyrics_solutio 100%[===================>] 693.81M  7.60MB/s    in 84s     \n",
      "\n",
      "2021-06-29 18:20:25 (8.29 MB/s) - ‘data_lyrics_solution.pickle’ saved [727513032/727513032]\n",
      "\n",
      "zsh:1: parse error near `>'\n"
     ]
    }
   ],
   "source": [
    "! wget \\\n",
    "'https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_lyrics_solution.pickle'\n",
    "\n",
    "import pickle\n",
    "with open(\"data_lyrics_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, y_train, X_test, y_test) = pickle.load(file)\n",
    "    \n",
    "! rm data_lyrics_solution.pickle -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **First, store your baseline accuracy to beat as `score_baseline`**\n",
    "- Consider predicting always the most frequent artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:33.555223Z",
     "start_time": "2021-06-25T17:22:33.547120Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "data[\"artist\"].value_counts()\n",
    "'''Baseline = most frequent artist / total amount = 1391/3031 = 45.89%'''\n",
    "score_baseline = 1391/3031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45892444737710325"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create a RNN architecture to predict the artists `y`  given verses `X`** :\n",
    "\n",
    "- Keep it simple: use only one LSTM layer and one *hidden* dense layer between the input and output layers\n",
    "- Don't forget to take care of fake \"zeros\" added during preprocessing\n",
    "- Store it into the `model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:27:09.448283Z",
     "start_time": "2021-06-25T17:27:08.796094Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(20, activation=\"tanh\"))\n",
    "    model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Train your `model` on the `(X_train, y_train)` training set**\n",
    "- Use an appropriate loss\n",
    "- Adapt the learning rate of your optimizer if convergence is too slow/fast\n",
    "- Make sure your model does not overfit with appropriate control techniques\n",
    "\n",
    "💡 You will not be judged by the computing power of your computer, you can reach decent performance in less than 3 minutes of training without GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2424, 300, 100)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2424, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.790957Z",
     "start_time": "2021-06-25T17:27:09.537171Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:668 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1153 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:868 _process_inputs\n        initial_state = self.get_initial_state(inputs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:650 get_initial_state\n        init_state = get_initial_state_fn(\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2516 get_initial_state\n        return list(_generate_zero_filled_state_for_cell(\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2998 _generate_zero_filled_state_for_cell\n        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3014 _generate_zero_filled_state\n        return nest.map_structure(create_zeros, state_size)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:867 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3011 create_zeros\n        return array_ops.zeros(init_state_size, dtype=dtype)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2911 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2960 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2896 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:5 prod\n        \n    /home/thechwal/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3030 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    /home/thechwal/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:867 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_4/lstm_4/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-7f88bc34c138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:668 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1153 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:868 _process_inputs\n        initial_state = self.get_initial_state(inputs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:650 get_initial_state\n        init_state = get_initial_state_fn(\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2516 get_initial_state\n        return list(_generate_zero_filled_state_for_cell(\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2998 _generate_zero_filled_state_for_cell\n        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3014 _generate_zero_filled_state\n        return nest.map_structure(create_zeros, state_size)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:867 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3011 create_zeros\n        return array_ops.zeros(init_state_size, dtype=dtype)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2911 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2960 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2896 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:5 prod\n        \n    /home/thechwal/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3030 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    /home/thechwal/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:867 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_4/lstm_4/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size= 32,\n",
    "                    validation_split=0.3,\n",
    "                    epochs=5,\n",
    "                   callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Plot the training and validation losses through training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.814449Z",
     "start_time": "2021-06-25T17:28:13.793297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot below your train/val loss history\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Run also this code to save figure as jpg in path below (it's your job to ensure it works)\n",
    "fig = plt.gcf()\n",
    "plt.savefig(\"tests/history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Save your accuracy on test set as `score_test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:29:15.350717Z",
     "start_time": "2021-06-25T17:29:14.925473Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Send your results below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:25:11.216908Z",
     "start_time": "2021-06-25T17:25:11.208773Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_nested_inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-8ba15cf32fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"network\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlayer_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfinal_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_api_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mno\u001b[0m \u001b[0minbound\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \"\"\"\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_nested_inputs'"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"network\",\n",
    "    loss = model.loss,\n",
    "    input_shape = list(model.input.shape),\n",
    "    layer_names = [layer.name for layer in model.layers],\n",
    "    final_activation = model.layers[-1].activation.__wrapped__._keras_api_names[0],\n",
    "    score_baseline = score_baseline,\n",
    "    score_test = score_test,\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "330.513px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
