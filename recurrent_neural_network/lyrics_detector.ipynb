{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics detector Challenge\n",
    "\n",
    "The goal for this challenge is to leverage your knowledge of Deep Learning to design and train a lyrics classifier. For a given verse $X$, our model should learn to predict the artist $y$. The dataset consists of lyrics scrapped from the Genius website.\n",
    "\n",
    "### Objectives:\n",
    "- Text preprocessing\n",
    "- Text embedding\n",
    "- Train a RNN to detect the artist behind a set of lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.205260Z",
     "start_time": "2021-06-25T17:22:11.396250Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "\n",
    "Our dataset contains around 4,000 verses of lyrics from different artists: Drake, Ed Sheeran and Kanye West (the verses are given in this order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.654079Z",
     "start_time": "2021-06-25T17:22:16.207433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah\n",
       "1          Drake  I'm makin' a change today The liquor been taki...\n",
       "2          Drake  I can't just be with you and only you Yeah, I ...\n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...\n",
       "4          Drake  I'm makin' a change today The liquor been taki...\n",
       "...          ...                                                ...\n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...\n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...\n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"\n",
       "3973  Kanye West  Like they still weren't looking at me like a r...\n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...\n",
       "\n",
       "[3975 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/verses.csv\")\n",
    "data = raw_data.copy() # From now on, update `data` as you see fit and don't touch raw_data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Have a look at the verse index 18th**. \n",
    "- What do you observe?\n",
    "- Clean verses from non standard characters using [`unidecode.unidecode()`](https://pypi.org/project/Unidecode/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unidecode in /home/thechwal/.local/lib/python3.8/site-packages (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"verse\"] = data[\"verse\"].apply(unidecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah\n",
       "1          Drake  I'm makin' a change today The liquor been taki...\n",
       "2          Drake  I can't just be with you and only you Yeah, I ...\n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...\n",
       "4          Drake  I'm makin' a change today The liquor been taki...\n",
       "...          ...                                                ...\n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...\n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...\n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"\n",
       "3973  Kanye West  Like they still weren't looking at me like a r...\n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...\n",
       "\n",
       "[3975 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Check if some verses are duplicated.** \n",
    "- It can be frequent in music lyrics.\n",
    "- If so, remove them to avoid data leaks between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.851521Z",
     "start_time": "2021-06-25T17:22:16.842793Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3975, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.861084Z",
     "start_time": "2021-06-25T17:22:16.854026Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_loading',\n",
    "    shape=data_cleaned.shape,\n",
    "    verses=data_cleaned.verse[:50]\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis (given to you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **We check the number of unique artist and the number of verses per artist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.182432Z",
     "start_time": "2021-06-25T17:22:19.175936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drake         1391\n",
       "Ed Sheeran     861\n",
       "Kanye West     779\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.artist.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **For each artist, let's have a look at the top-10 most used words to see if they look similar?**\n",
    "\n",
    "We'll use Tensorflow's [`Tokenizer`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)'s index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.191343Z",
     "start_time": "2021-06-25T17:22:19.184174Z"
    }
   },
   "outputs": [],
   "source": [
    "drake = data[data.artist =='Drake'].verse\n",
    "ed = data[data.artist =='Ed Sheeran'].verse\n",
    "kanye = data[data.artist =='Kanye West'].verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.438880Z",
     "start_time": "2021-06-25T17:22:19.193277Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_drake = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_ed = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_kanye = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer_drake.fit_on_texts(drake)\n",
    "tokenizer_ed.fit_on_texts(ed)\n",
    "tokenizer_kanye.fit_on_texts(kanye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.457776Z",
     "start_time": "2021-06-25T17:22:19.441016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drake</th>\n",
       "      <th>Ed Sheeran</th>\n",
       "      <th>Kanye West</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>me</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>my</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>to</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>me</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i'm</td>\n",
       "      <td>in</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>my</td>\n",
       "      <td>i'm</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Drake Ed Sheeran Kanye West\n",
       "1      i          i          i\n",
       "2    you        you        the\n",
       "3    the        the        you\n",
       "4    and        and        and\n",
       "5     to         me         to\n",
       "6      a         my          a\n",
       "7     it         to         my\n",
       "8     me          a         it\n",
       "9    i'm         in         me\n",
       "10    my        i'm         in"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={\n",
    "    \"Drake\": pd.Series(tokenizer_drake.index_word)[:10],\n",
    "    \"Ed Sheeran\": pd.Series(tokenizer_ed.index_word)[:10],\n",
    "    \"Kanye West\": pd.Series(tokenizer_kanye.index_word)[:10],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 **Let's quantify how much vocabulary do they have in common**\n",
    "\n",
    "- An artist **vocabulary** is the **set** of all unique used words\n",
    "- We compute the `ratio` of (i) the length of vocabulary they **share**, over (ii) the length of the **total** vocabulary of the dataset\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "We'll use Python [`set.intersection()`](https://www.programiz.com/python-programming/methods/set/intersection) and [`set.union()`](https://www.programiz.com/python-programming/methods/set/union)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.465228Z",
     "start_time": "2021-06-25T17:22:19.460132Z"
    }
   },
   "outputs": [],
   "source": [
    "drake_vocabulary = set(tokenizer_drake.index_word.values())\n",
    "ed_vocabulary = set(tokenizer_ed.index_word.values())\n",
    "kanye_vocabulary = set(tokenizer_kanye.index_word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.474902Z",
     "start_time": "2021-06-25T17:22:19.467454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.28% of the artists' vocabulary is common\n"
     ]
    }
   ],
   "source": [
    "common_vocabulary = drake_vocabulary.intersection(ed_vocabulary).intersection(kanye_vocabulary)\n",
    "global_vocabulary = drake_vocabulary.union(ed_vocabulary).union(kanye_vocabulary)\n",
    "\n",
    "ratio = len(common_vocabulary)/len(global_vocabulary)\n",
    "print(f\"{ratio*100:.2f}% of the artists' vocabulary is common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Word Embedding\n",
    "We now need to think about embedding our sentences into numbers. We will be using [`gensim.models.Word2Vec`](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) to embed each word of the sentence and concatenate the embeddings of the words forming the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Transform the list of strings (verses) into a list of word sequences (a word sequence is a list of words contained in a string)**\n",
    "- Store these sequences of words in a new column `data[\"seq\"]` in your dataframe\n",
    "- You can use `tensorflow.keras.preprocessing.text.text_to_word_sequence` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.569442Z",
     "start_time": "2021-06-25T17:22:19.478291Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-805f1f9ccfca>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"seq\"] = data[\"verse\"].apply(tf.keras.preprocessing.text.text_to_word_sequence)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data[\"seq\"] = data[\"verse\"].apply(tf.keras.preprocessing.text.text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "      <td>[ayy, woah, ayy, ayy, yeah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "      <td>[i, can't, just, be, with, you, and, only, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "      <td>[well, summer, all, i, did, was, rest, okay, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "      <td>[dame, was, like, yo, you, got, a, deal, with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "      <td>[then, one, day, i, just, went, ahead, and, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "      <td>[i, ain't, gonna, front, it's, kinda, hot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "      <td>[like, they, still, weren't, looking, at, me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "      <td>[you, gotta, be, under, an, umbrella, you'll, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse  \\\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah   \n",
       "1          Drake  I'm makin' a change today The liquor been taki...   \n",
       "2          Drake  I can't just be with you and only you Yeah, I ...   \n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...   \n",
       "4          Drake  I'm makin' a change today The liquor been taki...   \n",
       "...          ...                                                ...   \n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...   \n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...   \n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"   \n",
       "3973  Kanye West  Like they still weren't looking at me like a r...   \n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...   \n",
       "\n",
       "                                                    seq  \n",
       "0                           [ayy, woah, ayy, ayy, yeah]  \n",
       "1     [i'm, makin', a, change, today, the, liquor, b...  \n",
       "2     [i, can't, just, be, with, you, and, only, you...  \n",
       "3     [well, summer, all, i, did, was, rest, okay, a...  \n",
       "4     [i'm, makin', a, change, today, the, liquor, b...  \n",
       "...                                                 ...  \n",
       "3970  [dame, was, like, yo, you, got, a, deal, with,...  \n",
       "3971  [then, one, day, i, just, went, ahead, and, pl...  \n",
       "3972         [i, ain't, gonna, front, it's, kinda, hot]  \n",
       "3973  [like, they, still, weren't, looking, at, me, ...  \n",
       "3974  [you, gotta, be, under, an, umbrella, you'll, ...  \n",
       "\n",
       "[3031 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Let's check if we can cap the length of each sequences without losing too much information**\n",
    "- Plot the distribution of sequences lengths using the [`seaborn.kdeplot`](https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn-displot) function\n",
    "- Does it seem reasonable to limit ourself to 300 words per verse later on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.783874Z",
     "start_time": "2021-06-25T17:22:19.572393Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-03ec62810863>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"len\"]= data[\"seq\"].apply(lambda x : len(x))\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data[\"len\"]= data[\"seq\"].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f3bfffd34c0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data=data, x=\"len\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Keep only the first `300` words of each sequences to reduce the useless long tail of long verses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.797635Z",
     "start_time": "2021-06-25T17:22:19.786221Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-55c2bfd6189c>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"seq\"] = data[\"seq\"].apply(lambda x : x[:300])\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "data[\"seq\"] = data[\"seq\"].apply(lambda x : x[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "      <th>seq</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "      <td>[ayy, woah, ayy, ayy, yeah]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "      <td>[i, can't, just, be, with, you, and, only, you...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "      <td>[well, summer, all, i, did, was, rest, okay, a...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "      <td>[i'm, makin', a, change, today, the, liquor, b...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "      <td>[dame, was, like, yo, you, got, a, deal, with,...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "      <td>[then, one, day, i, just, went, ahead, and, pl...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "      <td>[i, ain't, gonna, front, it's, kinda, hot]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "      <td>[like, they, still, weren't, looking, at, me, ...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "      <td>[you, gotta, be, under, an, umbrella, you'll, ...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3031 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse  \\\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah   \n",
       "1          Drake  I'm makin' a change today The liquor been taki...   \n",
       "2          Drake  I can't just be with you and only you Yeah, I ...   \n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...   \n",
       "4          Drake  I'm makin' a change today The liquor been taki...   \n",
       "...          ...                                                ...   \n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...   \n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...   \n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"   \n",
       "3973  Kanye West  Like they still weren't looking at me like a r...   \n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...   \n",
       "\n",
       "                                                    seq  len  \n",
       "0                           [ayy, woah, ayy, ayy, yeah]    5  \n",
       "1     [i'm, makin', a, change, today, the, liquor, b...   60  \n",
       "2     [i, can't, just, be, with, you, and, only, you...   96  \n",
       "3     [well, summer, all, i, did, was, rest, okay, a...   65  \n",
       "4     [i'm, makin', a, change, today, the, liquor, b...   61  \n",
       "...                                                 ...  ...  \n",
       "3970  [dame, was, like, yo, you, got, a, deal, with,...   18  \n",
       "3971  [then, one, day, i, just, went, ahead, and, pl...  110  \n",
       "3972         [i, ain't, gonna, front, it's, kinda, hot]    7  \n",
       "3973  [like, they, still, weren't, looking, at, me, ...   68  \n",
       "3974  [you, gotta, be, under, an, umbrella, you'll, ...  165  \n",
       "\n",
       "[3031 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Train a `gensim.models.Word2Vec` model on your dataset** \n",
    "- You want to embed each word into vectors of dimension `100`\n",
    "- No words should be excluded\n",
    "- Give Word2Vec at least 50 epochs to be sure it converges\n",
    "- Store these lists of vectors in a new column `data[\"embed\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.0.1-cp38-cp38-manylinux1_x86_64.whl (23.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 5.8 MB/s eta 0:00:01    |█                               | 737 kB 7.1 MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /home/thechwal/.local/lib/python3.8/site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/thechwal/.local/lib/python3.8/site-packages (from gensim) (1.7.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.0.1 smart-open-5.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:26.587185Z",
     "start_time": "2021-06-25T17:22:19.799947Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thechwal/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from gensim.models import Word2Vec\n",
    "word2vec = Word2Vec(sentences=data['seq'], vector_size=100, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "    return np.array(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-7608788501c3>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"embed\"] = data['seq'].apply(lambda x : embed_sentence(word2vec, x))\n"
     ]
    }
   ],
   "source": [
    "data[\"embed\"] = data['seq'].apply(lambda x : embed_sentence(word2vec, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:27.636650Z",
     "start_time": "2021-06-25T17:22:27.634359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check \n",
    "assert len(data['embed']) == len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create your numpy array `X` of shape (number_of_verses, 300, 100)**\n",
    "\n",
    "- 300 words per verse (pad verses shorter than 300 with zeros at the end) \n",
    "- each words being a vector of size 100\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lewagon/data-images/master/DL/padding.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.272086Z",
     "start_time": "2021-06-25T17:22:27.638449Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(data['embed'], dtype='float32', padding='post', maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 300, 100)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create the numpy array `y` of shape `(n_verses, 3)` that contains the one-hot-encoded list of labels, for the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.394015Z",
     "start_time": "2021-06-25T17:22:28.274638Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y = ohe.fit_transform(data[[\"artist\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 We train/test split the dataset below for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.558686Z",
     "start_time": "2021-06-25T17:22:28.400774Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.803743Z",
     "start_time": "2021-06-25T17:22:29.563431Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_preprocessing',\n",
    "    n_zeros = np.sum(X == 0),\n",
    "    X_shape = X.shape,\n",
    "    y_shape = y.shape,\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 Run this code below if you haven't managed to build your own (X,Y) training sets. This will load them as solution\n",
    "\n",
    "```python\n",
    "! wget \\\n",
    "'https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_lyrics_solution.pickle'\n",
    "\n",
    "import pickle\n",
    "with open(\"data_lyrics_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, y_train, X_test, y_test) = pickle.load(file)\n",
    "    \n",
    "! rm data_lyrics_solution.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **First, store your baseline accuracy to beat as `score_baseline`**\n",
    "- Consider predicting always the most frequent artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:33.555223Z",
     "start_time": "2021-06-25T17:22:33.547120Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "data[\"artist\"].value_counts()\n",
    "'''Baseline = most frequent artist / total amount = 1391/3031 = 45.89%'''\n",
    "score_baseline = 1391/3031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45892444737710325"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Create a RNN architecture to predict the artists `y`  given verses `X`** :\n",
    "\n",
    "- Keep it simple: use only one LSTM layer and one *hidden* dense layer between the input and output layers\n",
    "- Don't forget to take care of fake \"zeros\" added during preprocessing\n",
    "- Store it into the `model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:27:09.448283Z",
     "start_time": "2021-06-25T17:27:08.796094Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(20, activation=\"tanh\"))\n",
    "    model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"rmsprop\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Train your `model` on the `(X_train, y_train)` training set**\n",
    "- Use an appropriate loss\n",
    "- Adapt the learning rate of your optimizer if convergence is too slow/fast\n",
    "- Make sure your model does not overfit with appropriate control techniques\n",
    "\n",
    "💡 You will not be judged by the computing power of your computer, you can reach decent performance in less than 3 minutes of training without GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2424, 300, 100)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2424, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.790957Z",
     "start_time": "2021-06-25T17:27:09.537171Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:668 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1153 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:868 _process_inputs\n        initial_state = self.get_initial_state(inputs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:650 get_initial_state\n        init_state = get_initial_state_fn(\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2516 get_initial_state\n        return list(_generate_zero_filled_state_for_cell(\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2998 _generate_zero_filled_state_for_cell\n        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3014 _generate_zero_filled_state\n        return nest.map_structure(create_zeros, state_size)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:867 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3011 create_zeros\n        return array_ops.zeros(init_state_size, dtype=dtype)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2911 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2960 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2896 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:5 prod\n        \n    /home/thechwal/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3030 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    /home/thechwal/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:867 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_2/lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-b61fe09c2fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:668 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1153 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:868 _process_inputs\n        initial_state = self.get_initial_state(inputs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:650 get_initial_state\n        init_state = get_initial_state_fn(\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2516 get_initial_state\n        return list(_generate_zero_filled_state_for_cell(\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:2998 _generate_zero_filled_state_for_cell\n        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3014 _generate_zero_filled_state\n        return nest.map_structure(create_zeros, state_size)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:867 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:3011 create_zeros\n        return array_ops.zeros(init_state_size, dtype=dtype)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2911 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2960 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2896 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:5 prod\n        \n    /home/thechwal/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3030 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    /home/thechwal/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /home/thechwal/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:867 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_2/lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "history = model.fit(X_train, y_train,validation_split=0.3, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Plot the training and validation losses through training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.814449Z",
     "start_time": "2021-06-25T17:28:13.793297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot below your train/val loss history\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Run also this code to save figure as jpg in path below (it's your job to ensure it works)\n",
    "fig = plt.gcf()\n",
    "plt.savefig(\"tests/history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Save your accuracy on test set as `score_test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:29:15.350717Z",
     "start_time": "2021-06-25T17:29:14.925473Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 **Send your results below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:25:11.216908Z",
     "start_time": "2021-06-25T17:25:11.208773Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"network\",\n",
    "    loss = model.loss,\n",
    "    input_shape = list(model.input.shape),\n",
    "    layer_names = [layer.name for layer in model.layers],\n",
    "    final_activation = model.layers[-1].activation.__wrapped__._keras_api_names[0],\n",
    "    score_baseline = score_baseline,\n",
    "    score_test = score_test,\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "330.513px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
